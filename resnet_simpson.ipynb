{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbc77b43",
   "metadata": {
    "id": "cbc77b43"
   },
   "source": [
    "# 라이브러리 Import 및 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TXdCmlNyzl1x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXdCmlNyzl1x",
    "outputId": "34381e3a-9e4f-4bd3-eec3-b2abe69c4900"
   },
   "outputs": [],
   "source": [
    "#!pip install addict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1eedcc1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "b1eedcc1",
    "outputId": "4c17da7c-23a3-4842-f4d9-e33ea72aa553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  2.5.1+cu121\n",
      "Torchvision Version:  0.20.1+cu121\n",
      "Pillow Version:  11.1.0\n",
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.backends import cudnn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "import random\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import argparse, yaml\n",
    "from addict import Dict\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "print(\"PyTorch Version: \", torch.__version__)\n",
    "print(\"Torchvision Version: \", torchvision.__version__)\n",
    "print(\"Pillow Version: \", PIL.__version__)\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10bb5c9",
   "metadata": {
    "id": "a10bb5c9"
   },
   "source": [
    "### config 변수 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78eca193",
   "metadata": {
    "id": "78eca193"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'config.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m         cfg \u001b[38;5;241m=\u001b[39m Dict(yaml\u001b[38;5;241m.\u001b[39msafe_load(f))\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cfg\n\u001b[1;32m---> 12\u001b[0m cfg \u001b[38;5;241m=\u001b[39m \u001b[43mget_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m, in \u001b[0;36mget_cfg\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m args, _ \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_known_args()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# args.config 에 지정된 YAML 파일 읽어서 Dict 형태로 반환\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      9\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m Dict(yaml\u001b[38;5;241m.\u001b[39msafe_load(f))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cfg\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'config.yaml'"
     ]
    }
   ],
   "source": [
    "#config 불러오기\n",
    "def get_cfg():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--config\", type=str, default=\"config.yaml\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # args.config 에 지정된 YAML 파일 읽어서 Dict 형태로 반환\n",
    "    with open(args.config) as f:\n",
    "        cfg = Dict(yaml.safe_load(f))\n",
    "    return cfg\n",
    "\n",
    "cfg = get_cfg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176c781",
   "metadata": {
    "id": "d176c781"
   },
   "outputs": [],
   "source": [
    "#전역 시드 고정\n",
    "\n",
    "def set_global_seed(seed):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae17bb",
   "metadata": {
    "id": "64ae17bb"
   },
   "outputs": [],
   "source": [
    "set_global_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f4dd60",
   "metadata": {
    "id": "77f4dd60"
   },
   "source": [
    "### config 변수 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e1453",
   "metadata": {
    "id": "7a2e1453"
   },
   "outputs": [],
   "source": [
    "# random seed\n",
    "seed            = cfg.seed\n",
    "# train_split ratio\n",
    "train_split     = cfg.data.train_split\n",
    "# train_split random seed\n",
    "random_state    = cfg.data.random_state\n",
    "batch_size      = cfg.data.batch_size\n",
    "num_workers     = cfg.data.num_workers\n",
    "input_size      = cfg.data.input_size\n",
    "\n",
    "model_name      = cfg.model.name\n",
    "pretrained      = cfg.model.pretrained\n",
    "# feature_extract = False - 전체 모델 학습\n",
    "# feature_extract = True - Fc 레이어만 학습\n",
    "feature_extract = cfg.model.feature_extract\n",
    "\n",
    "optimizer_name  = cfg.training.optimizer\n",
    "lr              = cfg.training.lr\n",
    "momentum        = cfg.training.momentum\n",
    "weight_decay    = cfg.training.weight_decay\n",
    "scheduler_type  = cfg.training.scheduler\n",
    "step_size       = cfg.training.step_size\n",
    "gamma           = cfg.training.gamma\n",
    "num_epochs      = cfg.training.epochs\n",
    "\n",
    "random_flip     = cfg.augmentation.random_flip\n",
    "color_jitter    = cfg.augmentation.color_jitter\n",
    "cutmix          = cfg.augmentation.cutmix\n",
    "\n",
    "patience        = cfg.earlystopping.patience\n",
    "verbose         = cfg.earlystopping.verbose\n",
    "delta           = cfg.earlystopping.delta\n",
    "es_path         = cfg.earlystopping.es_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d691ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"./log/train.log\"),     # 파일로 기록\n",
    "        logging.StreamHandler(sys.stdout)     # 콘솔에도 출력\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b9d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Configuration: seed={seed}, model={model_name}, \"\n",
    "             f\"epochs={num_epochs}, lr={lr}, \"\n",
    "             f\"batch_size={batch_size}, \" f\"input_size={input_size},\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01526ff4",
   "metadata": {
    "id": "01526ff4"
   },
   "source": [
    "# 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f02f2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13f02f2c",
    "outputId": "36d99928-8d4a-4b2e-f5ad-6c11b0dced92"
   },
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"alexattia/the-simpsons-characters-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1b15a4",
   "metadata": {
    "id": "cb1b15a4"
   },
   "outputs": [],
   "source": [
    "train_dir = Path('/kaggle/input/the-simpsons-characters-dataset/simpsons_dataset/simpsons_dataset')\n",
    "test_dir = Path('/kaggle/input/the-simpsons-characters-dataset/kaggle_simpson_testset/kaggle_simpson_testset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df52ad",
   "metadata": {
    "id": "20df52ad"
   },
   "outputs": [],
   "source": [
    "class TrainValTestSplit():\n",
    "\n",
    "  def __init__(self, train_dir, test_dir):\n",
    "\n",
    "    self.train_dir = train_dir\n",
    "    self.test_dir = test_dir\n",
    "    # 하위 디렉토리를 순회하며 이미지의 경로를 리스트로 저장\n",
    "    self.train_val_files_path = sorted(list(self.train_dir.rglob('*.jpg')))\n",
    "    self.test_path = sorted(list(self.test_dir.rglob('*.jpg')))\n",
    "    self.train_val_labels = [path.parent.name for path in self.train_val_files_path]\n",
    "\n",
    "  def get_path(self):\n",
    "\n",
    "    train_files_path, val_files_path = train_test_split(self.train_val_files_path, test_size = 0.3, \\\n",
    "                                          stratify=self.train_val_labels, random_state = 42)\n",
    "\n",
    "    train_val_files_path = {'train': train_files_path, 'val': val_files_path}\n",
    "\n",
    "    return train_val_files_path, self.test_path\n",
    "\n",
    "  def get_n_classes(self):\n",
    "    return len(np.unique(self.train_val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4858a087",
   "metadata": {
    "id": "4858a087"
   },
   "outputs": [],
   "source": [
    "TrainValTestPath = TrainValTestSplit(train_dir, test_dir)\n",
    "train_path, test_path = TrainValTestPath.get_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f0e02b",
   "metadata": {
    "id": "d3f0e02b"
   },
   "source": [
    "## 모델 학습 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gT4grHBe1cbT",
   "metadata": {
    "id": "gT4grHBe1cbT"
   },
   "source": [
    "### 조기종료 함수\n",
    "https://github.com/Bjarten/early-stopping-pytorch/blob/main/early_stopping_pytorch/early_stopping.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q8XMPSXS1bpE",
   "metadata": {
    "id": "Q8XMPSXS1bpE"
   },
   "outputs": [],
   "source": [
    "# 조기종료 함수\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self,\n",
    "                 patience: int = 7,\n",
    "                 delta: float = 0.0,\n",
    "                 path: str = 'checkpoint.pt',\n",
    "                 verbose: bool = False,\n",
    "                 trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_val_loss = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        # Check if validation loss is nan\n",
    "        if np.isnan(val_loss):\n",
    "            self.trace_func(\"Validation loss is NaN. Ignoring this epoch.\")\n",
    "            return\n",
    "\n",
    "        if self.best_val_loss is None:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss < self.best_val_loss - self.delta:\n",
    "            # Significant improvement detected\n",
    "            self.best_val_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0  # Reset counter since improvement occurred\n",
    "        else:\n",
    "            # No significant improvement\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decreases.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5574991",
   "metadata": {
    "id": "d5574991"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, save_best_weights_path, save_last_weights_path, num_epochs=cfg.training.epochs, is_inception=False, early_stopping=None):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    val_loss_history = []\n",
    "    train_acc_history = []\n",
    "    train_loss_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # train과 val 단계에 따라 model 모드 변경\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in tqdm_notebook(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # train 모드라면 hitstory 저장\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # inception module을 사용하는 모델인경우 loss 설정\n",
    "                    if is_inception and phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimizer train mode\n",
    "                    # scheduler의 경우 일단 비활성화\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        #scheduler.step()\n",
    "                        #lr_step = optimizer_ft.state_dict()[\"param_groups\"][0][\"lr\"]\n",
    "                        #lr_find_lr.append(lr_step)\n",
    "\n",
    "                # 현재 에포크의 손실 저장\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "            # loss, acc 계산\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # 현재 epoch의 정확도가 best_acc 보다 큰 경우 best 모델을 변경\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                # best model 저장장\n",
    "                torch.save(best_model_wts, save_best_weights_path)\n",
    "            # 현재 epoch의 정확도를 history에 저장\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc.item())\n",
    "                val_loss_history.append(epoch_loss)\n",
    "                #logging\n",
    "                logging.info(f\"Epoch {epoch}/{num_epochs-1} VAlID loss={epoch_loss:.4f} acc={epoch_acc:.4f}\")\n",
    "            else:\n",
    "                train_acc_history.append(epoch_acc.item())\n",
    "                train_loss_history.append(epoch_loss)\n",
    "                logging.info(f\"Epoch {epoch}/{num_epochs-1} TRAIN loss={epoch_loss:.4f} acc={epoch_acc:.4f}\")\n",
    "\n",
    "        torch.save(model.state_dict(), save_last_weights_path)\n",
    "        print()\n",
    "            \n",
    "        # epoch를 수행한 뒤 early stopping 조건 확인\n",
    "        if early_stopping is not None:\n",
    "            early_stopping(val_loss_history[-1], model)\n",
    "            if early_stopping.early_stop: # 조건 만족 시 조기 종료\n",
    "                break\n",
    "\n",
    "    # 학습시간 계산\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # best model 로드\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    history_val = {'loss': val_loss_history, 'acc': val_acc_history}\n",
    "    history_train = {'loss': train_loss_history, 'acc': train_acc_history}\n",
    "\n",
    "    return model, history_val, history_train, time_elapsed, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373cb8c7",
   "metadata": {
    "id": "373cb8c7"
   },
   "source": [
    "## transfer learning 시 동작 결정 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b5cf5f",
   "metadata": {
    "id": "f7b5cf5f"
   },
   "outputs": [],
   "source": [
    "# feature_extracting이 설정된 경우 fc레이어의 param만 학습\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbacbef",
   "metadata": {
    "id": "2bbacbef"
   },
   "source": [
    "## torch.models로부터 모델을 불러오는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ad56e",
   "metadata": {
    "id": "269ad56e"
   },
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained):\n",
    "\n",
    "    model_ft = None\n",
    "\n",
    "    if model_name == \"resnet152\":\n",
    "        \"\"\" Resnet152\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
    "        # feature_extract=true인 경우 마지막 fc레이어의 param만 학습\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        # fc레이어의 output 개수 설정\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        #model_ft.fc = nn.Sequantial(\n",
    "        #    nn.Dropout(p=0.5),\n",
    "        #    nn.Linear(num_ftrs, num_classes)\n",
    "        #)\n",
    "\n",
    "    elif model_name == \"resnet18\":\n",
    "        \"\"\" Resnet152\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        # feature_extract=true인 경우 마지막 fc레이어의 param만 학습\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        # fc레이어의 output 개수 설정\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484b6b4a",
   "metadata": {
    "id": "484b6b4a"
   },
   "source": [
    "## 데이터셋 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce1982",
   "metadata": {
    "id": "abce1982"
   },
   "outputs": [],
   "source": [
    "class SimpsonsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, files_path, data_transforms):\n",
    "      self.files_path = files_path\n",
    "      self.transform = data_transforms\n",
    "\n",
    "      if 'test' not in str(self.files_path[0]):\n",
    "        self.labels = [path.parent.name for path in self.files_path]\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.label_encoder.fit(self.labels)\n",
    "\n",
    "        with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
    "            pickle.dump(self.label_encoder, le_dump_file)\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.files_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "      img_path = str(self.files_path[idx])\n",
    "      image = Image.open(img_path)\n",
    "      image = self.transform(image)\n",
    "\n",
    "      if 'test' in str(self.files_path[0]):\n",
    "        return image\n",
    "      else:\n",
    "        label_str = str(self.files_path[idx].parent.name)\n",
    "        label = self.label_encoder.transform([label_str]).item()\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d865b48",
   "metadata": {
    "id": "8d865b48"
   },
   "source": [
    "# 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0a6473",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe0a6473",
    "outputId": "31596dee-77f1-438c-d77e-5fde2a16908c"
   },
   "outputs": [],
   "source": [
    "#fc_layer = 'all-st-SGD-m.9-nest-s-cycle-exp-.00001-.05-g.99994-m.8-.9'\n",
    "\n",
    "# device 설정\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 가중치 저장\n",
    "save_last_weights_path = '/kaggle/working/' + model_name + '-' + '_last_weights.pth'\n",
    "save_best_weights_path = '/kaggle/working/' + model_name + '-' + '_best_weights.pth'\n",
    "\n",
    "num_classes = TrainValTestPath.get_n_classes()\n",
    "\n",
    "model_ft = initialize_model(model_name, num_classes, feature_extract, pretrained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0614c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized-Mean Pooling (GeM)\n",
    "# avgpool -> p-norm pooling\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3.0, eps=1e-6): \n",
    "        super().__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        return F.adaptive_avg_pool2d(x.clamp(min=self.eps).pow(self.p), (1,1)).pow(1./self.p)\n",
    "# 교체\n",
    "model_ft.avgpool = GeM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84921c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0411a5eb",
   "metadata": {
    "id": "0411a5eb"
   },
   "source": [
    "# 데이터 Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c49a6f9",
   "metadata": {
    "id": "5c49a6f9"
   },
   "outputs": [],
   "source": [
    "# ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) -> imagenet 데이터셋의 통계 기반\n",
    "# TODO\n",
    "# simpson 데이터셋 전체의 std와 mean 계산 후 정규화에 이용\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((input_size,input_size)),\n",
    "        #transforms.CenterCrop(input_size),\n",
    "        transforms.RandomChoice( [\n",
    "                                  transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                  transforms.ColorJitter(contrast=0.9),\n",
    "                                  transforms.ColorJitter(brightness=0.1),\n",
    "                                  transforms.RandomApply( [ transforms.RandomHorizontalFlip(p=1), transforms.ColorJitter(contrast=0.9) ], p=0.5),\n",
    "                                  transforms.RandomApply( [ transforms.RandomHorizontalFlip(p=1), transforms.ColorJitter(brightness=0.1) ], p=0.5),\n",
    "                                  ] ),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((input_size,input_size)),\n",
    "        #transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1a007",
   "metadata": {
    "id": "eea1a007"
   },
   "source": [
    "# 모델에 전달될 데이터 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e795489",
   "metadata": {
    "id": "8e795489"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4815bbdb",
   "metadata": {
    "id": "4815bbdb"
   },
   "outputs": [],
   "source": [
    "image_datasets = {mode: SimpsonsDataset(train_path[mode], data_transforms[mode]) for mode in ['train', 'val']}\n",
    "image_datasets_test = SimpsonsDataset(test_path, data_transforms['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafd3ce",
   "metadata": {
    "id": "8eafd3ce"
   },
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d691a34",
   "metadata": {
    "id": "3d691a34"
   },
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "\n",
    "dataloaders_dict = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True,\n",
    "                                                         num_workers=num_workers, worker_init_fn=seed_worker,generator=g),\n",
    "                    'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True,\n",
    "                                                       num_workers=num_workers,worker_init_fn=seed_worker,generator=g)}\n",
    "dataloader_test = torch.utils.data.DataLoader(image_datasets_test, batch_size=batch_size, shuffle=False,\n",
    "                                              num_workers=num_workers, worker_init_fn=seed_worker,generator=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af8066c",
   "metadata": {
    "id": "0af8066c"
   },
   "source": [
    "### 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d127297",
   "metadata": {
    "id": "4d127297"
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt_ax.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt_ax.set_title(title)\n",
    "    plt_ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf2dd33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "adf2dd33",
    "outputId": "096c152a-a131-4659-e1db-f3ee417d5e26"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n",
    "                        sharey=True, sharex=True)\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0, 4500))\n",
    "    im_val, label = image_datasets['train'][random_characters]\n",
    "    # 캐릭터 이름 출력\n",
    "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
    "                image_datasets['val'].label_encoder.inverse_transform([label])[0].split('_')))\n",
    "    imshow(im_val.data.cpu(), \\\n",
    "          title=img_label,plt_ax=fig_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab5c79",
   "metadata": {
    "id": "04ab5c79"
   },
   "source": [
    "# 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe970c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "4dfe970c",
    "outputId": "fe4e1f87-1b98-4c63-d3c5-437ad866312d"
   },
   "outputs": [],
   "source": [
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name, param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            pass\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8bccf9",
   "metadata": {
    "id": "de8bccf9"
   },
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa84609",
   "metadata": {
    "id": "cfa84609"
   },
   "source": [
    "학습은\n",
    " lr_scheduler.CyclicLR를 이용해 최적의 lr 범위를 찾고\n",
    " 이를 이용하여 실제 학습하는 두 단계로 이루어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f1ef2e",
   "metadata": {
    "id": "52f1ef2e"
   },
   "source": [
    "## 1. lr 범위 결정\n",
    "\n",
    "Оптимизацию lr будем проводить используя циклическое изменение его значений в указанном диапазоне. Вначале необходимо определить оптимальные границы диапазона. Для этого проведем тестовый запуск. Выберем step size таким образом, чтобы во время тестового запуска lr линейно возрастал. <br>\n",
    "\n",
    "После чего построим график accuracy относительно learning rate, на основании графика выберем диапазон значений.\n",
    "\n",
    "Метод: https://arxiv.org/pdf/1506.01186.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef308ea",
   "metadata": {
    "id": "8ef308ea"
   },
   "outputs": [],
   "source": [
    "# base_lr = 0.00001\n",
    "# max_lr = 0.05\n",
    "# lr_find_epochs = 2\n",
    "\n",
    "# cost = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9, nesterov = True)\n",
    "\n",
    "# step_size = lr_find_epochs * len(dataloaders_dict['train'])\n",
    "\n",
    "# scheduler = optim.lr_scheduler.CyclicLR(optimizer_ft, base_lr = base_lr, max_lr = max_lr, step_size_up=step_size, mode='exp_range', gamma=0.99994, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1)\n",
    "\n",
    "# def search_lr(lr_find_epochs):\n",
    "\n",
    "#   accs = []\n",
    "#   lr_find_lr = []\n",
    "#   acc_sum = 0.0\n",
    "\n",
    "#   for i in range(lr_find_epochs):\n",
    "#     print(\"epoch {}\".format(i))\n",
    "#     for inputs, labels in tqdm_notebook(dataloaders_dict['train']):\n",
    "\n",
    "#       inputs = inputs.to(device)\n",
    "#       labels = labels.to(device)\n",
    "\n",
    "#       model_ft.train()\n",
    "#       optimizer_ft.zero_grad()\n",
    "\n",
    "#       outputs = model_ft(inputs)\n",
    "#       loss = cost(outputs, labels)\n",
    "#       preds = torch.argmax(outputs, 1)\n",
    "#       acc_running = torch.sum(preds == labels.data).item()\n",
    "#       acc_sum += torch.sum(preds == labels.data).item()\n",
    "\n",
    "#       loss.backward()\n",
    "#       optimizer_ft.step()\n",
    "#       scheduler.step()\n",
    "\n",
    "#       lr_step = optimizer_ft.state_dict()[\"param_groups\"][0][\"lr\"]\n",
    "#       lr_find_lr.append(lr_step)\n",
    "\n",
    "#       accs.append(acc_running)\n",
    "#   accs = np.array(accs) / acc_sum\n",
    "\n",
    "#   return lr_find_lr, accs\n",
    "\n",
    "# lr_find_lr, accs = search_lr(lr_find_epochs)\n",
    "\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.plot(np.array(lr_find_lr), np.array(accs));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f2baaa",
   "metadata": {
    "id": "78f2baaa"
   },
   "source": [
    "## 2. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94dd91",
   "metadata": {
    "collapsed": true,
    "id": "0d94dd91",
    "outputId": "6f2a25a0-7e09-4505-869a-39cf075fc0f4"
   },
   "outputs": [],
   "source": [
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name, param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            #print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            pass\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090abc7",
   "metadata": {
    "id": "4090abc7"
   },
   "outputs": [],
   "source": [
    "#base_lr = 0.0012\n",
    "#max_lr = 0.0022\n",
    "#num_epoch = 30\n",
    "\n",
    "cost = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer_ft = optim.SGD(params_to_update, lr=lr, momentum=momentum, nesterov = True)\n",
    "\n",
    "#weight_decay 추가\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=lr, momentum=momentum, nesterov = True, weight_decay = weight_decay)\n",
    "\n",
    "#step_size = 2 * math.ceil( len(dataloaders_dict['train']) / batch_size )\n",
    "#scheduler = optim.lr_scheduler.CyclicLR(optimizer_ft, base_lr = base_lr, max_lr = max_lr, step_size_up=step_size, mode='exp_range', gamma=0.994, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99fb14",
   "metadata": {
    "id": "2e99fb14"
   },
   "outputs": [],
   "source": [
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "best_acc = .0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc013347",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465,
     "referenced_widgets": [
      "cf65f7ed2f3e4fa48055f457509b5502",
      "917e6adf7408434ab36c2be82c454ed5",
      "bc6409f7ba3548448bdb64a5a8ecfefe",
      "d422dc09edec47769cc5dd8d8385f291",
      "745667c4c1a44d2db454b1e9206dffa6",
      "a735a117c1044c41b0cdd67487999cea",
      "033cf529832a45c1b35251948bfdc35f",
      "cf1f3aebfdbb4d05ac8eef00189cac4e",
      "420dd7c2065f43d09eca335a2e207c70",
      "3e7d2e9d9b9441e0b51bd17b96273f93",
      "f43bf6e3106e468d9586774eeb62c57f"
     ]
    },
    "id": "cc013347",
    "outputId": "97c2e718-0599-4d7e-9ad0-d652e64a043a"
   },
   "outputs": [],
   "source": [
    "#모델 훈련\n",
    "\n",
    "es = EarlyStopping(patience = cfg.early_stopping.patience, \n",
    "                   verbose = cfg.early_stopping.verbose, \n",
    "                   delta = cfg.early_stopping.delta\n",
    "                )\n",
    "\n",
    "#total_epochs = cfg.training.epochs\n",
    "\n",
    "model_ft, hist_val, hist_train, time_elapsed, best_acc = train_model(\n",
    "    model_ft,\n",
    "    dataloaders_dict,\n",
    "    cost,\n",
    "    optimizer_ft,\n",
    "    save_best_weights_path,\n",
    "    save_last_weights_path,\n",
    "    num_epochs,\n",
    "    early_stopping = es,\n",
    "    is_inception=(model_name == \"inception\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c41da2e",
   "metadata": {
    "id": "5c41da2e"
   },
   "source": [
    "# 학습 결과 및 모델 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98b585c",
   "metadata": {
    "id": "f98b585c"
   },
   "source": [
    "## 학습 결과 시각화 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e811fb",
   "metadata": {
    "id": "45e811fb"
   },
   "outputs": [],
   "source": [
    "# train/valid 학습 결과 loss/acc 분류\n",
    "val_loss = hist_val['loss']\n",
    "val_acc = hist_val['acc']\n",
    "train_loss = hist_train['loss']\n",
    "train_acc = hist_train['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14223b3b",
   "metadata": {
    "id": "14223b3b"
   },
   "outputs": [],
   "source": [
    "def visualization(train, val, is_loss = True):\n",
    "  if is_loss:\n",
    "    plt.figure(figsize=(9,5))\n",
    "    plt.plot(torch.tensor(train, device =  'cpu'), label = 'Training loss')\n",
    "    plt.plot(torch.tensor(val, device =  'cpu'), label = 'Val loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "  else:\n",
    "    plt.figure(figsize=(9,5))\n",
    "    plt.plot(torch.tensor(train, device =  'cpu'), label = 'Training acc')\n",
    "    plt.plot(torch.tensor(val, device =  'cpu'), label = 'Val acc')\n",
    "    plt.title('Training and validation acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Acc')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50121eda",
   "metadata": {
    "id": "50121eda"
   },
   "source": [
    "## confusion_matrix for val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ac678",
   "metadata": {
    "id": "eb5ac678"
   },
   "outputs": [],
   "source": [
    "def predict(model, test_loader):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = []\n",
    "\n",
    "        for inputs in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            model.eval()\n",
    "            outputs = model(inputs).cpu()\n",
    "            logits.append(outputs)\n",
    "\n",
    "    probs = nn.functional.softmax(torch.cat(logits), dim=1).numpy()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc10362",
   "metadata": {
    "id": "ffc10362"
   },
   "outputs": [],
   "source": [
    "def confusion_matrix():\n",
    "    # 실제 label 추출\n",
    "    actual = [image_datasets['val'][i][1] for i in range(len(image_datasets['val']) ) ]\n",
    "\n",
    "    # 이미지 추출\n",
    "    image = [image_datasets['val'][i][0] for i in range( len(image_datasets['val']) ) ]\n",
    "\n",
    "    img_conf_dataloader = torch.utils.data.DataLoader(image, batch_size=cfg.data.batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    #image_conf_dataloader의 이미지들의 확률 생성\n",
    "    probs = predict(model_ft, img_conf_dataloader)\n",
    "    #가장 높은 확률의 결과로 배열 생성\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "\n",
    "    # 테이블 생성\n",
    "    df = pd.DataFrame({'actual': actual, 'preds': preds})\n",
    "\n",
    "    confusion_matrix = pd.crosstab(df['actual'], df['preds'], rownames=['Actual'], colnames=['Predicted'], margins = False)\n",
    "\n",
    "    # 인코더 다운로드\n",
    "    label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
    "\n",
    "    # 클래스 목록 가져오기기\n",
    "    yticklabels = label_encoder.classes_\n",
    "\n",
    "    plt.subplots(figsize=(20,20))\n",
    "\n",
    "    # confusion matrix가 제대로 출력되지 않는 부분을 수정했습니다.\n",
    "    sn.heatmap(confusion_matrix, annot=True, fmt=\"d\", linewidths=0.5, cmap=\"YlGnBu\", cbar=False, vmax = 30, yticklabels = yticklabels, xticklabels = label_encoder.classes_[np.unique(preds)])\n",
    "    #sn.heatmap(confusion_matrix, annot=True, fmt=\"d\", linewidths=0.5, cmap=\"YlGnBu\", cbar=False, vmax = 30, yticklabels = yticklabels, xticklabels = yticklabels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3b44cb",
   "metadata": {
    "id": "af3b44cb",
    "outputId": "8ca29917-e8fd-408c-a525-b793dd0bcd36"
   },
   "outputs": [],
   "source": [
    "confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec01dbe",
   "metadata": {
    "id": "bec01dbe"
   },
   "source": [
    "## lr_cycle, acc, loss 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcda28cd",
   "metadata": {
    "id": "fcda28cd"
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(17,10))\n",
    "#plt.plot(lr_cycle);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c643a",
   "metadata": {
    "id": "f92c643a",
    "outputId": "38daccf8-ec49-42f6-eeca-2563d071d786"
   },
   "outputs": [],
   "source": [
    "visualization(train_acc, val_acc, is_loss = False)\n",
    "print('\\n')\n",
    "visualization(train_loss, val_loss, is_loss = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af69da2b",
   "metadata": {
    "id": "af69da2b"
   },
   "source": [
    "# 모델 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e374046",
   "metadata": {
    "id": "2e374046"
   },
   "source": [
    "## 샘플 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d0b49",
   "metadata": {
    "id": "d81d0b49"
   },
   "outputs": [],
   "source": [
    "def predict_one_sample(model, img_tensor, device=device):\n",
    "    with torch.no_grad():\n",
    "        img_tensor = img_tensor.to(device)\n",
    "        model.eval()\n",
    "        y_hat = model(img_tensor).cpu()\n",
    "        y_pred = torch.nn.functional.softmax(y_hat, dim=1).numpy()\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ee44d",
   "metadata": {
    "id": "582ee44d"
   },
   "source": [
    "## 테스트 샘플 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f263b50",
   "metadata": {
    "id": "7f263b50",
    "outputId": "1ae850d7-bea5-4fb4-93d3-7b87479ae4af"
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(12, 12), \\\n",
    "                        sharey=True, sharex=True)\n",
    "\n",
    "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
    "\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0, 1000))\n",
    "    im_val, label = image_datasets['val'][random_characters]\n",
    "    # inverse_transform은 LabelEncoder() 메서드로, 숫자에서 inverse_transform을 사용하여 클래스 이름을 반환\n",
    "    # 캐릭터 이름을 가져옴\n",
    "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
    "                image_datasets['val'].label_encoder.inverse_transform([label])[0].split('_')))\n",
    "\n",
    "    imshow(im_val.data.cpu(), \\\n",
    "          title=img_label, plt_ax=fig_x)\n",
    "\n",
    "    actual_text = \"Actual : {}\".format(img_label)\n",
    "\n",
    "    # 확률 출력할 영역 추가\n",
    "    fig_x.add_patch(patches.Rectangle((0, 53), 86, 35, color='white'))\n",
    "    font0 = FontProperties()\n",
    "    font = font0.copy()\n",
    "    font.set_family(\"fantasy\")\n",
    "    prob_pred = predict_one_sample(model_ft, im_val.unsqueeze(0))\n",
    "    # 확률 가져오기\n",
    "    predicted_proba = np.max(prob_pred)*100\n",
    "    y_pred = np.argmax(prob_pred)\n",
    "\n",
    "    predicted_label = label_encoder.classes_[y_pred]\n",
    "    predicted_label = predicted_label[:len(predicted_label)//2] + '\\n' + predicted_label[len(predicted_label)//2:]\n",
    "    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n",
    "\n",
    "    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\n",
    "                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710a36d",
   "metadata": {
    "id": "a710a36d",
    "outputId": "1c052944-4580-443d-afb9-7a50154642f5"
   },
   "outputs": [],
   "source": [
    "probs = predict(model_ft, dataloader_test)\n",
    "\n",
    "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
    "\n",
    "preds = label_encoder.inverse_transform(np.argmax(probs, axis = 1 ))\n",
    "test_file_names = [path.name for path in image_datasets_test.files_path]\n",
    "\n",
    "for i in range(len(test_file_names)):\n",
    "  test_file_names[i] = test_file_names[i].split('.')[0].rsplit('_', 1)[0]\n",
    "\n",
    "present_labels = np.unique(test_file_names)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_file_names, preds, labels=present_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a8c11",
   "metadata": {
    "id": "506a8c11"
   },
   "outputs": [],
   "source": [
    "#my_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n",
    "#my_submit.head()\n",
    "#my_submit.to_csv('simspsons.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "033cf529832a45c1b35251948bfdc35f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3e7d2e9d9b9441e0b51bd17b96273f93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "420dd7c2065f43d09eca335a2e207c70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "745667c4c1a44d2db454b1e9206dffa6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "917e6adf7408434ab36c2be82c454ed5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a735a117c1044c41b0cdd67487999cea",
      "placeholder": "​",
      "style": "IPY_MODEL_033cf529832a45c1b35251948bfdc35f",
      "value": "  0%"
     }
    },
    "a735a117c1044c41b0cdd67487999cea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc6409f7ba3548448bdb64a5a8ecfefe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf1f3aebfdbb4d05ac8eef00189cac4e",
      "max": 458,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_420dd7c2065f43d09eca335a2e207c70",
      "value": 1
     }
    },
    "cf1f3aebfdbb4d05ac8eef00189cac4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf65f7ed2f3e4fa48055f457509b5502": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_917e6adf7408434ab36c2be82c454ed5",
       "IPY_MODEL_bc6409f7ba3548448bdb64a5a8ecfefe",
       "IPY_MODEL_d422dc09edec47769cc5dd8d8385f291"
      ],
      "layout": "IPY_MODEL_745667c4c1a44d2db454b1e9206dffa6"
     }
    },
    "d422dc09edec47769cc5dd8d8385f291": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e7d2e9d9b9441e0b51bd17b96273f93",
      "placeholder": "​",
      "style": "IPY_MODEL_f43bf6e3106e468d9586774eeb62c57f",
      "value": " 1/458 [00:21&lt;1:38:46, 12.97s/it]"
     }
    },
    "f43bf6e3106e468d9586774eeb62c57f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
